{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generator Draft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reallygooday/60daysofudacity/blob/master/Text_Generator_Draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZc_EhL718cD",
        "colab_type": "text"
      },
      "source": [
        "https://www.springfieldspringfield.co.uk/episode_scripts.php?tv-show=sherlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQyA-0NKFFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "229c2108-4c2c-4e8f-df9a-e56d60abac35"
      },
      "source": [
        "#!wget -O oliver.txt https://www.fullbooks.com/Oliver-Twist1.html\n",
        "!wget -O oliver.txt http://www.gutenberg.org/cache/epub/730/pg730.txt"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 14:44:05--  http://www.gutenberg.org/cache/epub/730/pg730.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 936253 (914K) [text/plain]\n",
            "Saving to: ‘oliver.txt’\n",
            "\n",
            "oliver.txt          100%[===================>] 914.31K   325KB/s    in 2.8s    \n",
            "\n",
            "2019-07-29 14:44:08 (325 KB/s) - ‘oliver.txt’ saved [936253/936253]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2SKyZFl1ei_",
        "colab_type": "code",
        "outputId": "589c8547-ee59-4309-f93e-f8b03b95ecfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!wget -O sherlock.txt https://www.dropbox.com/s/od4a3cowfu3sezm/Sherlock_script.txt?dl=0"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 14:12:08--  https://www.dropbox.com/s/od4a3cowfu3sezm/Sherlock_script.txt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/od4a3cowfu3sezm/Sherlock_script.txt [following]\n",
            "--2019-07-29 14:12:09--  https://www.dropbox.com/s/raw/od4a3cowfu3sezm/Sherlock_script.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com/cd/0/inline/AlkVS5Ho1GWHHvZTpEe1vgOd_GxQwoUHSQ4G-LiVEK8k08xicV69xpCS7NRSHO2sz-yb7ucCeUMHBRpQgnlGo_VDm9vgzm8cMRY8laOtCsvxkQ/file# [following]\n",
            "--2019-07-29 14:12:09--  https://uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com/cd/0/inline/AlkVS5Ho1GWHHvZTpEe1vgOd_GxQwoUHSQ4G-LiVEK8k08xicV69xpCS7NRSHO2sz-yb7ucCeUMHBRpQgnlGo_VDm9vgzm8cMRY8laOtCsvxkQ/file\n",
            "Resolving uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com (uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com (uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 741017 (724K) [text/plain]\n",
            "Saving to: ‘sherlock.txt’\n",
            "\n",
            "sherlock.txt        100%[===================>] 723.65K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-07-29 14:12:10 (8.87 MB/s) - ‘sherlock.txt’ saved [741017/741017]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mUIz-wk13IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sherlock.txt', 'r') as f:\n",
        "  transcript = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQVMZkw13dK",
        "colab_type": "code",
        "outputId": "c961545b-5d46-4ec3-9fdd-840b7471ff07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#mounting google drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgUDrE3T2T9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "project_dir = \"/content/drive/My Drive/Text Generator\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0j2Hf8t2UmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = transcript.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692F2F4wCGz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bee21d2f-4542-4b34-b6ae-57cb9cb01ff9"
      },
      "source": [
        "!ls '/content/drive/My Drive/Text Generator'"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sherlock.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDpq6VT13xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_lengths = [len(line.split()) for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dHSOUP63pB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueWords(text):\n",
        "  words = text.lower().split()\n",
        "  return list(set(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9BgEp8N3pVC",
        "colab_type": "code",
        "outputId": "233c790c-80aa-4c36-fc24-8e53fad8a08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('number of lines: ', len(lines))\n",
        "print('average number of words in a sentence: ', round(np.average(line_lengths), 1))\n",
        "print('number of words: ', len(transcript.lower().split()))\n",
        "print('number of unique words: ', len(getUniqueWords(transcript)))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of lines:  15583\n",
            "average number of words in a sentence:  8.7\n",
            "number of words:  135946\n",
            "number of unique words:  15641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwv26eO3pqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueChars(text):\n",
        "  uniqueChars = list(set([char for char in text.lower()]))\n",
        "  uniqueChars.sort()\n",
        "  return uniqueChars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFZaqgW614Dx",
        "colab_type": "code",
        "outputId": "617147aa-4582-4922-fa7c-92471eaa07e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('There are {} unique characters in the dataset, counting lower and upper case letters as one letter'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 67 unique characters in the dataset, counting lower and upper case letters as one letter\n",
            "['\\n', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '\\x80', '\\x8d', '\\x99', '£', '©', '°', '½', 'â', 'ã', '\\ufeff']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1oTPqJ38T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def cleanupText(text):\n",
        "  wanted_chars = string.digits + string.ascii_letters + \"'\" + '\".,:;!?-() \\n'\n",
        "  print(wanted_chars)\n",
        "  return ''.join(x for x in text if x in (wanted_chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQlkeIP4BTa",
        "colab_type": "code",
        "outputId": "a311fc05-02cd-41a0-ddc4-2a99e68fcf7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transcript = cleanupText(transcript)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\".,:;!?-() \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnex6e3Q4Bm_",
        "colab_type": "code",
        "outputId": "fe6f9e12-7f6e-4b8f-ea25-2a5c08fc5b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('After cleanup there are {} unique characters in the dataset'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleanup there are 49 unique characters in the dataset\n",
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_33xCg4B4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation_dict = {\n",
        "        '.':'||period||',\n",
        "        ',':'||comma||',\n",
        "        '\"':'||quote||',\n",
        "        ';':'||semicolon||',\n",
        "        '!':'||exclamation||',\n",
        "        '?':'||question||',\n",
        "        '(':'||leftPar||',\n",
        "        ')':'||rightPar||',\n",
        "        '-':'||dash||',\n",
        "        '\\n':'||return||',\n",
        "        \"'\":'||single_quote||'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGdG0l638lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizePunctuation(text):\n",
        "  for key, value in punctuation_dict.items():\n",
        "    text = text.replace(key, ' {} '.format(value))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHmKr-Vp4RAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript = tokenizePunctuation(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnFQMCU4RSs",
        "colab_type": "code",
        "outputId": "fa1110ac-cd21-4319-d492-caa34bccd538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(transcript[:100])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ||dash|| ELLA: How ||single_quote|| s your blog going ||question||   ||dash|| Hmm ||comma||  fine |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGSER7D4Rp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words = getUniqueWords(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db1Nwxsl383Z",
        "colab_type": "code",
        "outputId": "1cc5cb64-4561-480f-b151-a9eba33bb52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The number of unique words is: ', len(unique_words))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words is:  8506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SeOFYN54mvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def createLookupTables(text, padding_symbol):\n",
        "  text = text.lower().split()\n",
        "  text.append(padding_symbol)\n",
        "  count = Counter(text)\n",
        "  vocabulary = sorted(count, key=count.get, reverse=True)\n",
        "  word_to_int = {word:idx for idx, word in enumerate(vocabulary)}\n",
        "  int_to_word = {idx:word for idx, word in enumerate(vocabulary)}\n",
        "  return (word_to_int,int_to_word)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDJNYby4pKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PADDING_SYMBOL = '<PAD>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVnyZIn4pf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_int,int_to_word = createLookupTables(transcript, PADDING_SYMBOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKxPTAHB4nBC",
        "colab_type": "code",
        "outputId": "02c7061b-526c-43e5-803b-c23af4d20246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(int_to_word[i])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "||return||\n",
            "||period||\n",
            "||comma||\n",
            "||single_quote||\n",
            "you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g38nRoJC402s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changeIntoInts(text):\n",
        "  return [word_to_int[word] for word in text.lower().split()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt6DnjhE41Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_int = changeIntoInts(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQbsIzJ41bH",
        "colab_type": "code",
        "outputId": "92bb9148-fe4c-4420-d6c8-6eb2d18edfd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(transcript_int[:20])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 4733, 55, 3, 10, 29, 388, 73, 5, 8, 170, 2, 215, 1, 0, 93, 1, 0, 98, 93]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSAhGWyC5Cti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKGsNSbv5C_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path):  \n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump((word_to_int, int_to_word, punctuation_dict, transcript_int), f)\n",
        "    print('Saved preprocessed data in', path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XV7T4bl5DQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed(path):\n",
        "  return pickle.load(open(path, mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZyrWI25NHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving current preprocessed data\n",
        "path = project_dir + 'preprocessed' + str(datetime.datetime.now()) +'.p'\n",
        "save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAV7lePL66lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def createDataloader(text_int, sequence_length, batch_size):\n",
        "  \n",
        "  #first we need to convert the whole dataset into features and targets lists\n",
        "  features, target = [], []\n",
        "  \n",
        "  #we loop through the whole dataset, moving one element at a time\n",
        "  #we start at the first element and end at the element that is sequence_length from the end of the dataset\n",
        "  \n",
        "  for sequence_no in range(len(text_int)-sequence_length):\n",
        "    features.append(text_int[sequence_no:sequence_no+sequence_length])\n",
        "    target.append(text_int[sequence_no+sequence_length])\n",
        "    \n",
        "  #then we convert the dataset into the Tensor Dataset, which accepts NumPy arrays as parameter\n",
        "  #Tensor Dataset needs features and target nparrays as parameters\n",
        "  \n",
        "  dataset = TensorDataset(torch.from_numpy(np.array(features)), torch.from_numpy(np.array(target)))\n",
        "\n",
        "  #once we have the appropriate dataset, we can create the dataloder\n",
        "  \n",
        "  dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
        "  \n",
        "  return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiUutag5663O",
        "colab_type": "code",
        "outputId": "9dc8ccbb-e422-486f-ad0e-a5a51bcc7da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sample_loader = createDataloader(transcript_int[:50], sequence_length=5, batch_size=10)\n",
        "sample_iterable = iter(sample_loader)\n",
        "sample_feature, sample_target = sample_iterable.next()\n",
        "\n",
        "print('Sample feature batch:')\n",
        "print(sample_feature)\n",
        "print('Sample target:')\n",
        "print(sample_target)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample feature batch:\n",
            "tensor([[  73,   12,  140,    4,   11],\n",
            "        [ 140,    4,   11,  425,   12],\n",
            "        [   8, 4733,   55,    3,   10],\n",
            "        [  11,  288,    1,    0,   65],\n",
            "        [   3,   10,   29,  388,   73],\n",
            "        [  93,    1,    0,   98,   93],\n",
            "        [ 183,    5,    8,   27,   11],\n",
            "        [   8,  170,    2,  215,    1],\n",
            "        [  12,  140,    4,   11,  425],\n",
            "        [   1,    0,   65,    2,    9]])\n",
            "Sample target:\n",
            "tensor([ 425, 3332,   29,    2,    5,    1,  288,    0,   12,    3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clhlRb667Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ScriptGenModel(nn.Module):\n",
        "  \n",
        "  #here we define the structure of the model\n",
        "  \n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "    super(ScriptGenModel, self).__init__()\n",
        "    \n",
        "    #saving the parameters for future use\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    # defining model layers\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "  #here we decide, how the forward pass of the model should be performed\n",
        "  \n",
        "  def forward(self, nn_input, hidden):\n",
        "    \n",
        "    batch_size = nn_input.size(0)\n",
        "\n",
        "    embeds = self.embedding(nn_input)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.fc(lstm_out)\n",
        "\n",
        "    out = out.view(batch_size, -1, self.output_size)\n",
        "    out = out[:, -1]\n",
        "    return out, hidden\n",
        "  \n",
        "  #here we define the way to initialise the hidden state\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e_qKNAO5NYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_back_prop(scriptGenModel, optimizer, criterion, inp, target, hidden):\n",
        "  # move data to GPU, if available\n",
        "  if(train_on_gpu):\n",
        "    inp, target = inp.cuda(), target.cuda()\n",
        "    \n",
        "  # perform backpropagation and optimization\n",
        "  hidden = tuple([each.data for each in hidden])\n",
        "\n",
        "  scriptGenModel.zero_grad()\n",
        "    \n",
        "  output, hidden = scriptGenModel(inp, hidden)\n",
        "\n",
        "  loss = criterion(output, target)\n",
        "  loss.backward()\n",
        "  nn.utils.clip_grad_norm_(scriptGenModel.parameters(), 3)\n",
        "  optimizer.step()\n",
        "  return loss.item(), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqK7KEa85Npu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    scriptGenModel.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "        \n",
        "        # initialize hidden state\n",
        "        hidden = scriptGenModel.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            \n",
        "            # make sure you iterate over completely full batches, only\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            # forward, back prop\n",
        "            loss, hidden = forward_back_prop(scriptGenModel, optimizer, criterion, inputs, labels, hidden)          \n",
        "            # record loss\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            # printing loss stats\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    # returns a trained rnn\n",
        "    return scriptGenModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM3w25Py7UrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for data preprocessing\n",
        "\n",
        "sequence_length = 8\n",
        "batch_size = 64\n",
        "\n",
        "# Training parameters\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model parameters\n",
        "\n",
        "vocab_size = len(word_to_int)\n",
        "output_size = vocab_size\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "\n",
        "show_every_n_batches = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqfP3HYo7U75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(filename, scriptGenModel):\n",
        "  model_save_name = filename + \".pt\"\n",
        "  path = project_dir + model_save_name\n",
        "  torch.save(scriptGenModel, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUFoleFr7VM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(filename):\n",
        "    path = project_dir + filename + \".pt\"\n",
        "    return torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJDb4uM7hjv",
        "colab_type": "code",
        "outputId": "f58f9f08-0d67-44f1-b31a-686e0792fdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checking if GPU is available\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "  print('There is no GPU available. Please consider switching to GPU for training the model.')\n",
        "else:\n",
        "  print(\"GPU available. You're good to go!\") "
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available. You're good to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90pTqbr71BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = createDataloader(transcript_int, sequence_length, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z14C2I6n7h1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creaing the model\n",
        "scriptGenModel = ScriptGenModel(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "\n",
        "#deciding on optimizer and loss functions\n",
        "optimizer = torch.optim.Adam(scriptGenModel.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57oiVck4nSj",
        "colab_type": "code",
        "outputId": "aad7f456-3a62-4eba-fcea-5fb2e900dada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(scriptGenModel)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ScriptGenModel(\n",
            "  (embedding): Embedding(8507, 300)\n",
            "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=512, out_features=8507, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkomUKF99kH3",
        "colab_type": "code",
        "outputId": "77da4aa8-3927-421e-8361-a7f68d2f9379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#moving the model to GPU if it's available\n",
        "if train_on_gpu:\n",
        "    scriptGenModel.cuda()\n",
        "\n",
        "#running the trainining loop\n",
        "trained_scriptGenModel = train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
        "\n",
        "#Setup for saving the trained model to Google Drive\n",
        "current_time = datetime.datetime.now() \n",
        "model_name = 'trained_scriptGenModel' + str(current_time)\n",
        "save_model(model_name, trained_scriptGenModel)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 10 epoch(s)...\n",
            "Epoch:    1/10    Loss: 5.209265849113464\n",
            "\n",
            "Epoch:    1/10    Loss: 4.698591610908508\n",
            "\n",
            "Epoch:    1/10    Loss: 4.5093682971000675\n",
            "\n",
            "Epoch:    1/10    Loss: 4.453822639465332\n",
            "\n",
            "Epoch:    1/10    Loss: 4.367384813308716\n",
            "\n",
            "Epoch:    1/10    Loss: 4.295944457530975\n",
            "\n",
            "Epoch:    2/10    Loss: 4.119138348602249\n",
            "\n",
            "Epoch:    2/10    Loss: 4.042986974716187\n",
            "\n",
            "Epoch:    2/10    Loss: 4.011648796081543\n",
            "\n",
            "Epoch:    2/10    Loss: 3.992278242111206\n",
            "\n",
            "Epoch:    2/10    Loss: 3.990391868114471\n",
            "\n",
            "Epoch:    2/10    Loss: 3.944023148059845\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7540049834879574\n",
            "\n",
            "Epoch:    3/10    Loss: 3.711089825153351\n",
            "\n",
            "Epoch:    3/10    Loss: 3.731899416446686\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7379342856407165\n",
            "\n",
            "Epoch:    3/10    Loss: 3.722172655582428\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7068832478523253\n",
            "\n",
            "Epoch:    4/10    Loss: 3.514253672011598\n",
            "\n",
            "Epoch:    4/10    Loss: 3.4726338987350465\n",
            "\n",
            "Epoch:    4/10    Loss: 3.4938424711227416\n",
            "\n",
            "Epoch:    4/10    Loss: 3.499097767829895\n",
            "\n",
            "Epoch:    4/10    Loss: 3.493121511459351\n",
            "\n",
            "Epoch:    4/10    Loss: 3.520160578250885\n",
            "\n",
            "Epoch:    5/10    Loss: 3.2932524120736266\n",
            "\n",
            "Epoch:    5/10    Loss: 3.247129964828491\n",
            "\n",
            "Epoch:    5/10    Loss: 3.296156245231628\n",
            "\n",
            "Epoch:    5/10    Loss: 3.290652785778046\n",
            "\n",
            "Epoch:    5/10    Loss: 3.305526124954224\n",
            "\n",
            "Epoch:    5/10    Loss: 3.3302517743110656\n",
            "\n",
            "Epoch:    6/10    Loss: 3.110586607884504\n",
            "\n",
            "Epoch:    6/10    Loss: 3.0497565126419066\n",
            "\n",
            "Epoch:    6/10    Loss: 3.094078167438507\n",
            "\n",
            "Epoch:    6/10    Loss: 3.142788080215454\n",
            "\n",
            "Epoch:    6/10    Loss: 3.1368090391159056\n",
            "\n",
            "Epoch:    6/10    Loss: 3.1798724336624145\n",
            "\n",
            "Epoch:    7/10    Loss: 2.955473127479325\n",
            "\n",
            "Epoch:    7/10    Loss: 2.902394381046295\n",
            "\n",
            "Epoch:    7/10    Loss: 2.9540697073936464\n",
            "\n",
            "Epoch:    7/10    Loss: 2.9764418234825136\n",
            "\n",
            "Epoch:    7/10    Loss: 2.988244507789612\n",
            "\n",
            "Epoch:    7/10    Loss: 3.031054385662079\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8057642555879263\n",
            "\n",
            "Epoch:    8/10    Loss: 2.749949369430542\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8149960317611695\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8542259624004362\n",
            "\n",
            "Epoch:    8/10    Loss: 2.867234737634659\n",
            "\n",
            "Epoch:    8/10    Loss: 2.9204917378425597\n",
            "\n",
            "Epoch:    9/10    Loss: 2.6941278928411223\n",
            "\n",
            "Epoch:    9/10    Loss: 2.6651110429763794\n",
            "\n",
            "Epoch:    9/10    Loss: 2.6889262895584105\n",
            "\n",
            "Epoch:    9/10    Loss: 2.7402232837677003\n",
            "\n",
            "Epoch:    9/10    Loss: 2.778386096715927\n",
            "\n",
            "Epoch:    9/10    Loss: 2.794996991157532\n",
            "\n",
            "Epoch:   10/10    Loss: 2.593979060649872\n",
            "\n",
            "Epoch:   10/10    Loss: 2.5639722232818603\n",
            "\n",
            "Epoch:   10/10    Loss: 2.612325105905533\n",
            "\n",
            "Epoch:   10/10    Loss: 2.63102684879303\n",
            "\n",
            "Epoch:   10/10    Loss: 2.657062320947647\n",
            "\n",
            "Epoch:   10/10    Loss: 2.7220891180038453\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ScriptGenModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SI2iGlk9kab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(scriptGenModel, prime_id, int_to_vocab, punctuation_dict, pad_value, predict_len=100):\n",
        "\n",
        "    scriptGenModel.eval()\n",
        "    \n",
        "    # create a sequence (batch_size=1) with the prime_id\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        if train_on_gpu:\n",
        "            current_seq = torch.LongTensor(current_seq).cuda()\n",
        "        else:\n",
        "            current_seq = torch.LongTensor(current_seq)\n",
        "        \n",
        "        # initialize the hidden state\n",
        "        hidden = scriptGenModel.init_hidden(current_seq.size(0))\n",
        "        \n",
        "        # get the output of the model\n",
        "        \n",
        "        ##### Added next 2 lines to fix numpy bug  ####\n",
        "        scriptGenModel.cpu()\n",
        "        current_seq = current_seq.cpu()\n",
        "        hidden = hidden[0].cpu(), hidden[1].cpu()\n",
        "        #print(\" curs:\", current_seq.device, \"hidden[0]\", hidden[0].device, \"hidden[1]\", hidden[1].device)\n",
        "        output, _ = scriptGenModel(current_seq, hidden)\n",
        "        \n",
        "        # get the next word probabilities\n",
        "        p = F.softmax(output, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "         \n",
        "        # use top_k sampling to get the index of the next word\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next word index with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        \n",
        "        # retrieve that word from the dictionary\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "        \n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = np.roll(current_seq, -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    # Replace punctuation tokens\n",
        "    for key, token in punctuation_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    \n",
        "    # return all the sentences\n",
        "    return gen_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzSPBGO9kxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2f5adcc-6455-431a-e33c-87d067143b2e"
      },
      "source": [
        "#we check if the parameters for text generation are loaded, and if not we load them in\n",
        "\n",
        "try:\n",
        "  if (word_to_int and int_to_word and punctuation_dict and PADDING_SYMBOL):\n",
        "    print('Data for text generation present')\n",
        "except:\n",
        "  path = project_dir+'preprocessed.p'\n",
        "  word_to_int, int_to_word, punctuation_dict, transcript_int = load_preprocessed(path)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for text generation present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZIUMnae90qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "452ab3eb-b7e4-4b2f-d5e1-f29b155d4786"
      },
      "source": [
        "#we check if the model is present, and if not we load it in\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  if (trained_scriptGenModel):\n",
        "    print('The model for text generation is present')\n",
        "except:\n",
        "  trained_scriptGenModel = load_model('trained_scriptGenModel')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model for text generation is present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hdks7hP96_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "b99a3760-d5bc-4e70-c8e4-5c61e6c2eede"
      },
      "source": [
        "gen_length = 500 \n",
        "prime_word = 'You'\n",
        "\n",
        "generated_script = generate(trained_scriptGenModel, word_to_int[prime_word.lower()], int_to_word, punctuation_dict, word_to_int[PADDING_SYMBOL], gen_length)\n",
        "print(generated_script)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you waltz to pick up with an index dick all the time.\n",
            "and you know, i' m not sure it' s a romantic attachment.\n",
            "- i don' t want to be right behind.\n",
            "i need you to tell him that this maniac is full of remarking.\n",
            "you' re not serious about quitting?!- what?- the crossbow?- i need you to do something that you can do, mr holmes, i can' t believe it.\n",
            "' please, if you' d better explain, you' ve got a hip.\n",
            "- you' ve got deadlines.\n",
            "- what?- i need you to see that damn pill.\n",
            "i don' t want to see you interact.\n",
            "i' ll be late, then.\n",
            "i' m sure sally came round, and it was a bitch.\n",
            "you know, they' re not suicides- i' m sorry, i' m not a hero.\n",
            "it' s a fake.\n",
            "- you' ve been youtubing- you' re going to miss your own.\n",
            "that' s why he' s just visiting with the police, and the largest man' s been explaining the same way, and i think you' re a proper genius.\n",
            "- why did you say?- well, i' m a killer.\n",
            "- why would you be surprised about this, john?- what?- i' m sorry?- no.\n",
            "- what?- nothing.\n",
            "- what?- i' m sorry.\n",
            "- you didn' t.\n",
            "- you didn' t.\n",
            "i' m sorry, i' ll be there if he' s alive.\n",
            "i' m a doctor.\n",
            "i don' t understand.\n",
            "- you know, you know.\n",
            "- you are, i' ll have you a candle.\n",
            "- i' m not involved.\n",
            "- why?- what?- i' m not laughing at you.\n",
            "you' re the one who shot him.\n",
            "i' ll tell him.\n",
            "i' m a businessman, acquiring assets.\n",
            "- i' ve got to go on, neptune.\n",
            "- i think you were going out for the state of a vengeful drama.\n",
            "the invisible man i saw you.\n",
            "and you can talk the police and dry, i think i' m not a hero you think you' d be dragged away, i' m going to go.\n",
            "' you'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerZQfgk97Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveGenScript(generated_script):\n",
        "  path = project_dir + 'generated_script' + str(datetime.datetime.now()) + '.txt'\n",
        "  with open(path, \"w\") as text_file:\n",
        "    text_file.write(generated_script)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVAg1cJl97mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveGenScript(generated_script)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Wqa_j_9075",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}