{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hemingway.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reallygooday/60daysofudacity/blob/master/Hemingway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_5-XQJw-GC8",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/12XhM8q_QG5wIZTfOFAdlD4GsXeMUPrhB#scrollTo=2_5-XQJw-GC8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjfzYkdbpxlp",
        "colab_type": "code",
        "outputId": "5b96d6c5-bd52-4ecb-a0eb-3676c5806757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIu1sgZtvQyp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac422aab-b9e7-4b5d-d643-3cbd64da2608",
        "id": "blVgZ_jUw1T7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Text Generator'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'generated_script2019-07-30 17:15:13.735175.txt'\n",
            " oliver.txt\n",
            " place2.txt\n",
            " place.txt\n",
            "'preprocessed2019-07-30 17:06:00.732826.p'\n",
            "'preprocessed2019-07-30 17:06:42.389736.p'\n",
            "'preprocessed2019-07-30 17:14:12.698497.p'\n",
            "'trained_scriptGenModel2019-07-30 17:15:09.497845.pt'\n",
            "'trained_scriptGenModel2019-07-30 17:16:10.999422.pt'\n",
            "'trained_scriptGenModel2019-07-30 17:16:37.995327.pt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mUIz-wk13IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Text Generator/place.txt', 'r') as f:\n",
        "  transcript = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0j2Hf8t2UmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = transcript.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDpq6VT13xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_lengths = [len(line.split()) for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dHSOUP63pB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueWords(text):\n",
        "  words = text.lower().split()\n",
        "  return list(set(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9BgEp8N3pVC",
        "colab_type": "code",
        "outputId": "0240c8a6-e8e8-4c8d-cfab-23aaf2e879f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('number of lines: ', len(lines))\n",
        "print('average number of words in a sentence: ', round(np.average(line_lengths), 1))\n",
        "print('number of words: ', len(transcript.lower().split()))\n",
        "print('number of unique words: ', len(getUniqueWords(transcript)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of lines:  406\n",
            "average number of words in a sentence:  3.5\n",
            "number of words:  1441\n",
            "number of unique words:  552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwv26eO3pqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueChars(text):\n",
        "  uniqueChars = list(set([char for char in text.lower()]))\n",
        "  uniqueChars.sort()\n",
        "  return uniqueChars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFZaqgW614Dx",
        "colab_type": "code",
        "outputId": "cf0ed2a2-40aa-4e68-921c-e62908225265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('There are {} unique characters in the dataset, counting lower and upper case letters as one letter'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 35 unique characters in the dataset, counting lower and upper case letters as one letter\n",
            "['\\n', ' ', '\"', \"'\", ',', '-', '.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', '\\ufeff']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1oTPqJ38T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def cleanupText(text):\n",
        "  wanted_chars = string.digits + string.ascii_letters + \"'\" + '\".,:;!?-() \\n'\n",
        "  print(wanted_chars)\n",
        "  return ''.join(x for x in text if x in (wanted_chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQlkeIP4BTa",
        "colab_type": "code",
        "outputId": "ea81c6c3-b0f8-44cd-e101-d559cf6f2877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transcript = cleanupText(transcript)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\".,:;!?-() \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnex6e3Q4Bm_",
        "colab_type": "code",
        "outputId": "98eeeb96-03b0-4f12-9f68-75a62d9435e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('After cleanup there are {} unique characters in the dataset'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleanup there are 34 unique characters in the dataset\n",
            "['\\n', ' ', '\"', \"'\", ',', '-', '.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_33xCg4B4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation_dict = {\n",
        "        '.':'||period||',\n",
        "        ',':'||comma||',\n",
        "        '\"':'||quote||',\n",
        "        ';':'||semicolon||',\n",
        "        '!':'||exclamation||',\n",
        "        '?':'||question||',\n",
        "        '(':'||leftPar||',\n",
        "        ')':'||rightPar||',\n",
        "        '-':'||dash||',\n",
        "        '\\n':'||return||',\n",
        "        \"'\":'||single_quote||'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGdG0l638lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizePunctuation(text):\n",
        "  for key, value in punctuation_dict.items():\n",
        "    text = text.replace(key, ' {} '.format(value))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHmKr-Vp4RAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript = tokenizePunctuation(transcript)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnFQMCU4RSs",
        "colab_type": "code",
        "outputId": "d363314c-908b-427e-ee8d-c464906feed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(transcript[:200])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It was late and every one had left the cafe except an old man  ||return|| who sat in the shadow the leaves of the tree made against the  ||return|| electric light ||period||  In the day time the stree\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGSER7D4Rp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words = getUniqueWords(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db1Nwxsl383Z",
        "colab_type": "code",
        "outputId": "414c71f8-6906-495f-e306-4b4688a2c09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The number of unique words is: ', len(unique_words))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words is:  421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SeOFYN54mvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def createLookupTables(text, padding_symbol):\n",
        "  text = text.lower().split()\n",
        "  text.append(padding_symbol)\n",
        "  count = Counter(text)\n",
        "  vocabulary = sorted(count, key=count.get, reverse=True)\n",
        "  word_to_int = {word:idx for idx, word in enumerate(vocabulary)}\n",
        "  int_to_word = {idx:word for idx, word in enumerate(vocabulary)}\n",
        "  return (word_to_int,int_to_word)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDJNYby4pKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PADDING_SYMBOL = '<PAD>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVnyZIn4pf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_int,int_to_word = createLookupTables(transcript, PADDING_SYMBOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKxPTAHB4nBC",
        "colab_type": "code",
        "outputId": "40c5fe97-56de-4ed8-c9ef-ecde6eb1ffad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(int_to_word[i])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "||return||\n",
            "||quote||\n",
            "||period||\n",
            "the\n",
            "he\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g38nRoJC402s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changeIntoInts(text):\n",
        "  return [word_to_int[word] for word in text.lower().split()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt6DnjhE41Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_int = changeIntoInts(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQbsIzJ41bH",
        "colab_type": "code",
        "outputId": "89f256fd-8bc6-4618-eaf8-7b4130fd9f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(transcript_int[:20])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 11, 76, 6, 131, 77, 78, 196, 3, 39, 132, 55, 18, 19, 0, 32, 79, 24, 3, 93]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSAhGWyC5Cti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKGsNSbv5C_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path):  \n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump((word_to_int, int_to_word, punctuation_dict, transcript_int), f)\n",
        "    print('Saved preprocessed data in', path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XV7T4bl5DQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed(path):\n",
        "  return pickle.load(open(path, mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8wEs1Rc51F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "project_dir = \"/content/drive/My Drive/Text Generator/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZyrWI25NHk",
        "colab_type": "code",
        "outputId": "86ccf80f-ec8e-408c-bb66-34bb5b369693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#saving current preprocessed data\n",
        "path = project_dir + 'preprocessed' + str(datetime.datetime.now()) +'.p'\n",
        "save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved preprocessed data in /content/drive/My Drive/Text Generator/preprocessed2019-07-30 17:17:30.349953.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O2G_Bw002eJY",
        "colab": {}
      },
      "source": [
        "def save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path):  \n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump((word_to_int, int_to_word, punctuation_dict, transcript_int), f)\n",
        "    print('Saved preprocessed data in', path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TCC3Z5PN2jCd",
        "colab": {}
      },
      "source": [
        "def load_preprocessed(path):\n",
        "  return pickle.load(open(path, mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAV7lePL66lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def createDataloader(text_int, sequence_length, batch_size):\n",
        "  \n",
        "  #first we need to convert the whole dataset into features and targets lists\n",
        "  features, target = [], []\n",
        "  \n",
        "  #we loop through the whole dataset, moving one element at a time\n",
        "  #we start at the first element and end at the element that is sequence_length from the end of the dataset\n",
        "  \n",
        "  for sequence_no in range(len(text_int)-sequence_length):\n",
        "    features.append(text_int[sequence_no:sequence_no+sequence_length])\n",
        "    target.append(text_int[sequence_no+sequence_length])\n",
        "    \n",
        "  #then we convert the dataset into the Tensor Dataset, which accepts NumPy arrays as parameter\n",
        "  #Tensor Dataset needs features and target nparrays as parameters\n",
        "  \n",
        "  dataset = TensorDataset(torch.from_numpy(np.array(features)), torch.from_numpy(np.array(target)))\n",
        "\n",
        "  #once we have the appropriate dataset, we can create the dataloder\n",
        "  \n",
        "  dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
        "  \n",
        "  return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiUutag5663O",
        "colab_type": "code",
        "outputId": "e31fd4f3-0ac8-42e9-b905-c2daf83e6997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sample_loader = createDataloader(transcript_int[:50], sequence_length=5, batch_size=10)\n",
        "sample_iterable = iter(sample_loader)\n",
        "sample_feature, sample_target = sample_iterable.next()\n",
        "\n",
        "print('Sample feature batch:')\n",
        "print(sample_feature)\n",
        "print('Sample target:')\n",
        "print(sample_target)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample feature batch:\n",
            "tensor([[  3, 198, 199,   3,  56],\n",
            "        [  3,  94,  22,   3, 133],\n",
            "        [  2,  24,   3, 198, 199],\n",
            "        [197, 134,   3,   0, 135],\n",
            "        [  3,  39, 132,  55,  18],\n",
            "        [196,   3,  39, 132,  55],\n",
            "        [ 18,  19,   0,  32,  79],\n",
            "        [ 26,   0,  33,   3, 201],\n",
            "        [132,  55,  18,  19,   0],\n",
            "        [  6, 131,  77,  78, 196]])\n",
            "Sample target:\n",
            "tensor([ 11, 197,   3,  43,  19,  18,  24, 202,  32,   3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clhlRb667Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ScriptGenModel(nn.Module):\n",
        "  \n",
        "  #here we define the structure of the model\n",
        "  \n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "    super(ScriptGenModel, self).__init__()\n",
        "    \n",
        "    #saving the parameters for future use\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    # defining model layers\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "  #here we decide, how the forward pass of the model should be performed\n",
        "  \n",
        "  def forward(self, nn_input, hidden):\n",
        "    \n",
        "    batch_size = nn_input.size(0)\n",
        "\n",
        "    embeds = self.embedding(nn_input)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.fc(lstm_out)\n",
        "\n",
        "    out = out.view(batch_size, -1, self.output_size)\n",
        "    out = out[:, -1]\n",
        "    return out, hidden\n",
        "  \n",
        "  #here we define the way to initialise the hidden state\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e_qKNAO5NYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_back_prop(scriptGenModel, optimizer, criterion, inp, target, hidden):\n",
        "  # move data to GPU, if available\n",
        "  if(train_on_gpu):\n",
        "    inp, target = inp.cuda(), target.cuda()\n",
        "    \n",
        "  # perform backpropagation and optimization\n",
        "  hidden = tuple([each.data for each in hidden])\n",
        "\n",
        "  scriptGenModel.zero_grad()\n",
        "    \n",
        "  output, hidden = scriptGenModel(inp, hidden)\n",
        "\n",
        "  loss = criterion(output, target)\n",
        "  loss.backward()\n",
        "  nn.utils.clip_grad_norm_(scriptGenModel.parameters(), 3)\n",
        "  optimizer.step()\n",
        "  return loss.item(), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqK7KEa85Npu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    scriptGenModel.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "        \n",
        "        # initialize hidden state\n",
        "        hidden = scriptGenModel.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            \n",
        "            # make sure you iterate over completely full batches, only\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            # forward, back prop\n",
        "            loss, hidden = forward_back_prop(scriptGenModel, optimizer, criterion, inputs, labels, hidden)          \n",
        "            # record loss\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            # printing loss stats\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    # returns a trained rnn\n",
        "    return scriptGenModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM3w25Py7UrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for data preprocessing\n",
        "\n",
        "sequence_length = 8\n",
        "batch_size = 64\n",
        "\n",
        "# Training parameters\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model parameters\n",
        "\n",
        "vocab_size = len(word_to_int)\n",
        "output_size = vocab_size\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "\n",
        "show_every_n_batches = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqfP3HYo7U75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(filename, scriptGenModel):\n",
        "  model_save_name = filename + \".pt\"\n",
        "  path = project_dir + model_save_name\n",
        "  torch.save(scriptGenModel, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUFoleFr7VM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(filename):\n",
        "    path = project_dir + filename + \".pt\"\n",
        "    return torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJDb4uM7hjv",
        "colab_type": "code",
        "outputId": "0e22e72f-c2f4-436d-e9e8-3f13b4f39b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checking if GPU is available\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "  print('There is no GPU available. Please consider switching to GPU for training the model.')\n",
        "else:\n",
        "  print(\"GPU available. You're good to go!\") "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available. You're good to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90pTqbr71BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = createDataloader(transcript_int, sequence_length, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z14C2I6n7h1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creaing the model\n",
        "scriptGenModel = ScriptGenModel(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "\n",
        "#deciding on optimizer and loss functions\n",
        "optimizer = torch.optim.Adam(scriptGenModel.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57oiVck4nSj",
        "colab_type": "code",
        "outputId": "6db4d7a1-bb15-4bb5-9410-a02c225aae9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(scriptGenModel)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ScriptGenModel(\n",
            "  (embedding): Embedding(422, 300)\n",
            "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=512, out_features=422, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkomUKF99kH3",
        "colab_type": "code",
        "outputId": "ffa70a31-450e-474d-ce9e-40ee3b5b0025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#moving the model to GPU if it's available\n",
        "if train_on_gpu:\n",
        "    scriptGenModel.cuda()\n",
        "\n",
        "#running the trainining loop\n",
        "trained_scriptGenModel = train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
        "\n",
        "#Setup for saving the trained model to Google Drive\n",
        "current_time = datetime.datetime.now() \n",
        "model_name = 'trained_scriptGenModel' + str(current_time)\n",
        "save_model(model_name, trained_scriptGenModel)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 10 epoch(s)...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ScriptGenModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SI2iGlk9kab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(scriptGenModel, prime_id, int_to_vocab, punctuation_dict, pad_value, predict_len=100):\n",
        "\n",
        "    scriptGenModel.eval()\n",
        "    \n",
        "    # create a sequence (batch_size=1) with the prime_id\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        if train_on_gpu:\n",
        "            current_seq = torch.LongTensor(current_seq).cuda()\n",
        "        else:\n",
        "            current_seq = torch.LongTensor(current_seq)\n",
        "        \n",
        "        # initialize the hidden state\n",
        "        hidden = scriptGenModel.init_hidden(current_seq.size(0))\n",
        "        \n",
        "        # get the output of the model\n",
        "        \n",
        "        ##### Added next 2 lines to fix numpy bug  ####\n",
        "        scriptGenModel.cpu()\n",
        "        current_seq = current_seq.cpu()\n",
        "        hidden = hidden[0].cpu(), hidden[1].cpu()\n",
        "        #print(\" curs:\", current_seq.device, \"hidden[0]\", hidden[0].device, \"hidden[1]\", hidden[1].device)\n",
        "        output, _ = scriptGenModel(current_seq, hidden)\n",
        "        \n",
        "        # get the next word probabilities\n",
        "        p = F.softmax(output, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "         \n",
        "        # use top_k sampling to get the index of the next word\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next word index with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        \n",
        "        # retrieve that word from the dictionary\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "        \n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = np.roll(current_seq, -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    # Replace punctuation tokens\n",
        "    for key, token in punctuation_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    \n",
        "    # return all the sentences\n",
        "    return gen_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzSPBGO9kxK",
        "colab_type": "code",
        "outputId": "1871596c-fe86-402f-e6f9-a0a21fafd8a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#we check if the parameters for text generation are loaded, and if not we load them in\n",
        "\n",
        "try:\n",
        "  if (word_to_int and int_to_word and punctuation_dict and PADDING_SYMBOL):\n",
        "    print('Data for text generation present')\n",
        "except:\n",
        "  path = project_dir+'preprocessed.p'\n",
        "  word_to_int, int_to_word, punctuation_dict, transcript_int = load_preprocessed(path)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for text generation present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hdks7hP96_G",
        "colab_type": "code",
        "outputId": "6f77259e-20f9-4048-9bb0-0dd2adf3f1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gen_length = 500 \n",
        "prime_word = 'What'\n",
        "\n",
        "generated_script = generate(trained_scriptGenModel, word_to_int[prime_word.lower()], int_to_word, punctuation_dict, word_to_int[PADDING_SYMBOL], gen_length)\n",
        "print(generated_script)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what.\"\n",
            "\n",
            "\n",
            "\" what do you want?\"\n",
            "\n",
            "\n",
            "\" no. you have everything.\"\n",
            "\n",
            "\n",
            "\" no,\" the waiter said. the waiter went away.\n",
            "\n",
            "\n",
            "\" no,\" the waiter said. the old man looked at the street. the street\n",
            "light shone on the number on the street where the street,\n",
            "leaving half to a peseta. he\n",
            "\n",
            "\n",
            "the old man looked at him.\" i know.\"\n",
            "\n",
            "\n",
            "\" no, hombre,\" the waiter said. the waiter went over him him down.\"\n",
            "\n",
            "\n",
            "\" what should you want to look him.\"\n",
            "\n",
            "\n",
            "\" i should have killed yourself last i week.\" he said.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\" no.\"\n",
            "\n",
            "\n",
            "\" i want to go home to bed. i am never get into before o o' clock. he kind of a wife waiting in bed\n",
            "for me.\"\n",
            "\n",
            "\n",
            "\" i'' m not.\" the waiter\n",
            "who. the waiter took the bottle inside the street and looked at the table\n",
            "with a wife pressure coffee too.\n",
            "\n",
            "\n",
            "\" no. finished.\"\n",
            "\n",
            "\n",
            "\" no, hombre, he would go at to his colleague.\"\n",
            "\n",
            "\n",
            "\" what about?\"\n",
            "\n",
            "\n",
            "\" you have everything.\"\n",
            "\n",
            "\n",
            "\" you have everything i have.\"\n",
            "\n",
            "\n",
            "\" he' m drunk every night,\" said the younger and went went over. the old man motioned with his wife,.\"\n",
            "\n",
            "\n",
            "\" i want to go to bed.\"\n",
            "\n",
            "\n",
            "\" you do not want mu-\n",
            "sic. nor can you stand a soldier with a shining steam pressure machine machine.\n",
            "\n",
            "\n",
            "\" what did he do he want?\"\n",
            "\n",
            "\n",
            "\" i' s tell.\"\n",
            "\n",
            "\n",
            "\" i' s tell him.\"\n",
            "\n",
            "\n",
            "\" he hung himself with a wife.\"\n",
            "\n",
            "\n",
            "\" he' s plenty. he can do not want to go to bed.\"\n",
            "\n",
            "\n",
            "\" you have everything.\"\n",
            "\n",
            "\n",
            "\" you should' t tell. he might buy better a wife.\"\n",
            "\n",
            "\n",
            "\" he' s lonely. i have a never waiting before in\n",
            "the light is very bright and pleas-\n",
            "ant. you have everything.\"\n",
            "\n",
            "\n",
            "\" he' s every every.\"\n",
            "\n",
            "\n",
            "\" he' s drunk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg6fl5Wzr7Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "74d26308-581e-4326-de00-bfdf921679c1",
        "id": "3YsnEAMZ9QJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gen_length = 500 \n",
        "prime_word = 'Man'\n",
        "\n",
        "generated_script = generate(trained_scriptGenModel, word_to_int[prime_word.lower()], int_to_word, punctuation_dict, word_to_int[PADDING_SYMBOL], gen_length)\n",
        "print(generated_script)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man.\"\n",
            "\n",
            "\n",
            "\" no,\" said the waiter.\n",
            "\n",
            "\n",
            "\" he' s plenty. i am all a very and a clean and pleasant\n",
            "out. the guard will went up him.\"\n",
            "\n",
            "\n",
            "\" what do you do?\"\n",
            "\n",
            "\n",
            "\" he had a wife once too.\"\n",
            "\n",
            "\n",
            "\" he' s drunk every him.\"\n",
            "\n",
            "\n",
            "\" you want' t you want to stay that at him.\" you have everything.\"\n",
            "\n",
            "\n",
            "\" i' t want to look at him.\"\n",
            "\n",
            "\n",
            "\" you should have killed last last last week, he he would deaf home. he\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\" no, hombre,\" he said. the old man looked at\n",
            "him. the waiter went over to him.\n",
            "\n",
            "\n",
            "\" no,\" said the old man.\n",
            "\n",
            "\n",
            "\" no. i have never confidence. i never get to bed before three\n",
            "o' s. he would lie the bed and finally to him down\n",
            "\" the waiter wiped the edge of the tree of the tree and made in the\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\" no,\" the waiter said. he was only in a hurry.\n",
            "\n",
            "\n",
            "\" what about?\"\n",
            "\n",
            "\n",
            "the barman watched him go him.\"\n",
            "\n",
            "\n",
            "\" no, you, you do not want mu-\n",
            "sic. nor can you stand before a bar with dignity although that\n",
            "\n",
            "is are that is provided for these hours. he might be better with a wife.\"\n",
            "\n",
            "\n",
            "\" no. i am reluctant to up up because because he said to himself. it is a clean and pleasant\n",
            "cafe. it is only\n",
            "and pleasant but the bar is clean-\n",
            "polished,\" he said, speaking with that that was all a hurry\n",
            "man walking unsteadily, they, there kept on, he said, speaking from his metal again.\n",
            "\n",
            "\n",
            "\" what do you want?\"\n",
            "\n",
            "\n",
            "\" he' s drunk plenty.\"\n",
            "\n",
            "\n",
            "\" what do you want?\" the old man was a little\n",
            "thing.\"\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\" he stays up the shutters.\" no more tonight. close now.\"\n",
            "\n",
            "\n",
            "\" you want?\"\n",
            "\n",
            "\n",
            "\" no, hombre, only to make a\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}