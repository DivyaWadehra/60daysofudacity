{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generator Oliver Twist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reallygooday/60daysofudacity/blob/master/Text_Generator_Oliver_Twist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9bH0U0EWv-K",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://machinetalk.org/2019/02/08/text-generation-with-pytorch/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQyA-0NKFFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "229c2108-4c2c-4e8f-df9a-e56d60abac35"
      },
      "source": [
        "#!wget -O oliver.txt https://www.fullbooks.com/Oliver-Twist1.html\n",
        "!wget -O oliver.txt http://www.gutenberg.org/cache/epub/730/pg730.txt"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 14:44:05--  http://www.gutenberg.org/cache/epub/730/pg730.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 936253 (914K) [text/plain]\n",
            "Saving to: ‘oliver.txt’\n",
            "\n",
            "oliver.txt          100%[===================>] 914.31K   325KB/s    in 2.8s    \n",
            "\n",
            "2019-07-29 14:44:08 (325 KB/s) - ‘oliver.txt’ saved [936253/936253]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2SKyZFl1ei_",
        "colab_type": "code",
        "outputId": "589c8547-ee59-4309-f93e-f8b03b95ecfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!wget -O sherlock.txt https://www.dropbox.com/s/od4a3cowfu3sezm/Sherlock_script.txt?dl=0"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 14:12:08--  https://www.dropbox.com/s/od4a3cowfu3sezm/Sherlock_script.txt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/od4a3cowfu3sezm/Sherlock_script.txt [following]\n",
            "--2019-07-29 14:12:09--  https://www.dropbox.com/s/raw/od4a3cowfu3sezm/Sherlock_script.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com/cd/0/inline/AlkVS5Ho1GWHHvZTpEe1vgOd_GxQwoUHSQ4G-LiVEK8k08xicV69xpCS7NRSHO2sz-yb7ucCeUMHBRpQgnlGo_VDm9vgzm8cMRY8laOtCsvxkQ/file# [following]\n",
            "--2019-07-29 14:12:09--  https://uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com/cd/0/inline/AlkVS5Ho1GWHHvZTpEe1vgOd_GxQwoUHSQ4G-LiVEK8k08xicV69xpCS7NRSHO2sz-yb7ucCeUMHBRpQgnlGo_VDm9vgzm8cMRY8laOtCsvxkQ/file\n",
            "Resolving uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com (uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com (uc86a4b70f7fefe0e8e295258e29.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 741017 (724K) [text/plain]\n",
            "Saving to: ‘sherlock.txt’\n",
            "\n",
            "sherlock.txt        100%[===================>] 723.65K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-07-29 14:12:10 (8.87 MB/s) - ‘sherlock.txt’ saved [741017/741017]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mUIz-wk13IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('oliver.txt', 'r') as f:\n",
        "  transcript = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQVMZkw13dK",
        "colab_type": "code",
        "outputId": "67c008a5-cbe1-4e78-b08d-d45c2d71c11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#mounting google drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgUDrE3T2T9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "project_dir = \"/content/drive/My Drive/Text Generator\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0j2Hf8t2UmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = transcript.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "692F2F4wCGz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd7dcca5-f6db-4214-db47-ad3b22cd6892"
      },
      "source": [
        "!ls '/content/drive/My Drive/Text Generator'"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oliver.txt  sherlock.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDpq6VT13xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_lengths = [len(line.split()) for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dHSOUP63pB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueWords(text):\n",
        "  words = text.lower().split()\n",
        "  return list(set(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9BgEp8N3pVC",
        "colab_type": "code",
        "outputId": "c97943fd-ed07-40cb-981b-ff1aa1de5a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print('number of lines: ', len(lines))\n",
        "print('average number of words in a sentence: ', round(np.average(line_lengths), 1))\n",
        "print('number of words: ', len(transcript.lower().split()))\n",
        "print('number of unique words: ', len(getUniqueWords(transcript)))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of lines:  19203\n",
            "average number of words in a sentence:  8.4\n",
            "number of words:  161009\n",
            "number of unique words:  20501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZwv26eO3pqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUniqueChars(text):\n",
        "  uniqueChars = list(set([char for char in text.lower()]))\n",
        "  uniqueChars.sort()\n",
        "  return uniqueChars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFZaqgW614Dx",
        "colab_type": "code",
        "outputId": "9a33fb44-1644-45c6-d8cb-6b37f5faf263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('There are {} unique characters in the dataset, counting lower and upper case letters as one letter'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 59 unique characters in the dataset, counting lower and upper case letters as one letter\n",
            "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1oTPqJ38T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def cleanupText(text):\n",
        "  wanted_chars = string.digits + string.ascii_letters + \"'\" + '\".,:;!?-() \\n'\n",
        "  print(wanted_chars)\n",
        "  return ''.join(x for x in text if x in (wanted_chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpQlkeIP4BTa",
        "colab_type": "code",
        "outputId": "2c633f08-c23b-4334-f6d2-28df4ffa94b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "transcript = cleanupText(transcript)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\".,:;!?-() \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnex6e3Q4Bm_",
        "colab_type": "code",
        "outputId": "eb890a2e-0dcd-453b-8c8c-82ef4ada2483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print('After cleanup there are {} unique characters in the dataset'.format(len(getUniqueChars(transcript))))\n",
        "print(getUniqueChars(transcript))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After cleanup there are 49 unique characters in the dataset\n",
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_33xCg4B4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation_dict = {\n",
        "        '.':'||period||',\n",
        "        ',':'||comma||',\n",
        "        '\"':'||quote||',\n",
        "        ';':'||semicolon||',\n",
        "        '!':'||exclamation||',\n",
        "        '?':'||question||',\n",
        "        '(':'||leftPar||',\n",
        "        ')':'||rightPar||',\n",
        "        '-':'||dash||',\n",
        "        '\\n':'||return||',\n",
        "        \"'\":'||single_quote||'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGdG0l638lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizePunctuation(text):\n",
        "  for key, value in punctuation_dict.items():\n",
        "    text = text.replace(key, ' {} '.format(value))\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHmKr-Vp4RAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript = tokenizePunctuation(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUnFQMCU4RSs",
        "colab_type": "code",
        "outputId": "aab9e7cf-796e-4fab-bce7-658f27bc3884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(transcript[:100])"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Project Gutenberg EBook of Oliver Twist ||comma||  by Charles Dickens ||return||  ||return|| Thi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGSER7D4Rp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique_words = getUniqueWords(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db1Nwxsl383Z",
        "colab_type": "code",
        "outputId": "1cc5cb64-4561-480f-b151-a9eba33bb52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('The number of unique words is: ', len(unique_words))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words is:  8506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SeOFYN54mvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def createLookupTables(text, padding_symbol):\n",
        "  text = text.lower().split()\n",
        "  text.append(padding_symbol)\n",
        "  count = Counter(text)\n",
        "  vocabulary = sorted(count, key=count.get, reverse=True)\n",
        "  word_to_int = {word:idx for idx, word in enumerate(vocabulary)}\n",
        "  int_to_word = {idx:word for idx, word in enumerate(vocabulary)}\n",
        "  return (word_to_int,int_to_word)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXDJNYby4pKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PADDING_SYMBOL = '<PAD>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgVnyZIn4pf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_int,int_to_word = createLookupTables(transcript, PADDING_SYMBOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKxPTAHB4nBC",
        "colab_type": "code",
        "outputId": "c6704e16-e285-4c6b-8398-766faf7ff704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(int_to_word[i])"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "||return||\n",
            "||comma||\n",
            "||single_quote||\n",
            "the\n",
            "||period||\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g38nRoJC402s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changeIntoInts(text):\n",
        "  return [word_to_int[word] for word in text.lower().split()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt6DnjhE41Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transcript_int = changeIntoInts(transcript)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQbsIzJ41bH",
        "colab_type": "code",
        "outputId": "e5dc6d08-dc8f-4142-e746-c3b907a1da70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(transcript_int[:20])"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 250, 244, 1371, 7, 32, 305, 1, 35, 1480, 2960, 0, 0, 33, 1371, 39, 25, 3, 432, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSAhGWyC5Cti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKGsNSbv5C_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path):  \n",
        "  with open(path, 'wb') as f:\n",
        "    pickle.dump((word_to_int, int_to_word, punctuation_dict, transcript_int), f)\n",
        "    print('Saved preprocessed data in', path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XV7T4bl5DQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed(path):\n",
        "  return pickle.load(open(path, mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZyrWI25NHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e42e1a2-99db-4cd9-b917-523c4a7dbd8c"
      },
      "source": [
        "#saving current preprocessed data\n",
        "path = project_dir + 'preprocessed' + str(datetime.datetime.now()) +'.p'\n",
        "save_preprocessed(word_to_int, int_to_word, punctuation_dict, transcript_int, path)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved preprocessed data in /content/drive/My Drive/Text Generatorpreprocessed2019-07-29 14:56:05.194814.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAV7lePL66lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def createDataloader(text_int, sequence_length, batch_size):\n",
        "  \n",
        "  #first we need to convert the whole dataset into features and targets lists\n",
        "  features, target = [], []\n",
        "  \n",
        "  #we loop through the whole dataset, moving one element at a time\n",
        "  #we start at the first element and end at the element that is sequence_length from the end of the dataset\n",
        "  \n",
        "  for sequence_no in range(len(text_int)-sequence_length):\n",
        "    features.append(text_int[sequence_no:sequence_no+sequence_length])\n",
        "    target.append(text_int[sequence_no+sequence_length])\n",
        "    \n",
        "  #then we convert the dataset into the Tensor Dataset, which accepts NumPy arrays as parameter\n",
        "  #Tensor Dataset needs features and target nparrays as parameters\n",
        "  \n",
        "  dataset = TensorDataset(torch.from_numpy(np.array(features)), torch.from_numpy(np.array(target)))\n",
        "\n",
        "  #once we have the appropriate dataset, we can create the dataloder\n",
        "  \n",
        "  dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
        "  \n",
        "  return dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiUutag5663O",
        "colab_type": "code",
        "outputId": "40bd6514-ad3c-4f4e-a620-0feaaf8eeb3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "sample_loader = createDataloader(transcript_int[:50], sequence_length=5, batch_size=10)\n",
        "sample_iterable = iter(sample_loader)\n",
        "sample_feature, sample_target = sample_iterable.next()\n",
        "\n",
        "print('Sample feature batch:')\n",
        "print(sample_feature)\n",
        "print('Sample target:')\n",
        "print(sample_target)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample feature batch:\n",
            "tensor([[  39,   25,    3,  432,    7],\n",
            "        [   1,  251,   15,  133,   50],\n",
            "        [  32,  305,    1,   35, 1480],\n",
            "        [ 251,   15,  133,   50,    0],\n",
            "        [  46, 1815,    5,   19,    0],\n",
            "        [  25,    3,  432,    7, 2529],\n",
            "        [   0,  294,   46, 4500, 2961],\n",
            "        [   0,   33, 1371,   39,   25],\n",
            "        [  29,   46, 1815,    5,   19],\n",
            "        [2961,    4,   17,  156, 1194]])\n",
            "Sample target:\n",
            "tensor([2529,    0, 2960,  228,  294, 2530,    4,    3,    0,   15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clhlRb667Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ScriptGenModel(nn.Module):\n",
        "  \n",
        "  #here we define the structure of the model\n",
        "  \n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "    super(ScriptGenModel, self).__init__()\n",
        "    \n",
        "    #saving the parameters for future use\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "        \n",
        "    # defining model layers\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "  #here we decide, how the forward pass of the model should be performed\n",
        "  \n",
        "  def forward(self, nn_input, hidden):\n",
        "    \n",
        "    batch_size = nn_input.size(0)\n",
        "\n",
        "    embeds = self.embedding(nn_input)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.fc(lstm_out)\n",
        "\n",
        "    out = out.view(batch_size, -1, self.output_size)\n",
        "    out = out[:, -1]\n",
        "    return out, hidden\n",
        "  \n",
        "  #here we define the way to initialise the hidden state\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if (train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e_qKNAO5NYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_back_prop(scriptGenModel, optimizer, criterion, inp, target, hidden):\n",
        "  # move data to GPU, if available\n",
        "  if(train_on_gpu):\n",
        "    inp, target = inp.cuda(), target.cuda()\n",
        "    \n",
        "  # perform backpropagation and optimization\n",
        "  hidden = tuple([each.data for each in hidden])\n",
        "\n",
        "  scriptGenModel.zero_grad()\n",
        "    \n",
        "  output, hidden = scriptGenModel(inp, hidden)\n",
        "\n",
        "  loss = criterion(output, target)\n",
        "  loss.backward()\n",
        "  nn.utils.clip_grad_norm_(scriptGenModel.parameters(), 3)\n",
        "  optimizer.step()\n",
        "  return loss.item(), hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqK7KEa85Npu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    scriptGenModel.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "        \n",
        "        # initialize hidden state\n",
        "        hidden = scriptGenModel.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            \n",
        "            # make sure you iterate over completely full batches, only\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            # forward, back prop\n",
        "            loss, hidden = forward_back_prop(scriptGenModel, optimizer, criterion, inputs, labels, hidden)          \n",
        "            # record loss\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            # printing loss stats\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    # returns a trained rnn\n",
        "    return scriptGenModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM3w25Py7UrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for data preprocessing\n",
        "\n",
        "sequence_length = 8\n",
        "batch_size = 64\n",
        "\n",
        "# Training parameters\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model parameters\n",
        "\n",
        "vocab_size = len(word_to_int)\n",
        "output_size = vocab_size\n",
        "embedding_dim = 300\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "\n",
        "show_every_n_batches = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqfP3HYo7U75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(filename, scriptGenModel):\n",
        "  model_save_name = filename + \".pt\"\n",
        "  path = project_dir + model_save_name\n",
        "  torch.save(scriptGenModel, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUFoleFr7VM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(filename):\n",
        "    path = project_dir + filename + \".pt\"\n",
        "    return torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJDb4uM7hjv",
        "colab_type": "code",
        "outputId": "64e4f0f1-80b8-4ad5-ac1a-e4e77b5e7a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#checking if GPU is available\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "  print('There is no GPU available. Please consider switching to GPU for training the model.')\n",
        "else:\n",
        "  print(\"GPU available. You're good to go!\") "
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available. You're good to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M90pTqbr71BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = createDataloader(transcript_int, sequence_length, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z14C2I6n7h1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creaing the model\n",
        "scriptGenModel = ScriptGenModel(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "\n",
        "#deciding on optimizer and loss functions\n",
        "optimizer = torch.optim.Adam(scriptGenModel.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57oiVck4nSj",
        "colab_type": "code",
        "outputId": "7c7b9f1c-be69-4116-ba1d-cfb8a2ad08d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(scriptGenModel)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ScriptGenModel(\n",
            "  (embedding): Embedding(10875, 300)\n",
            "  (lstm): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=512, out_features=10875, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkomUKF99kH3",
        "colab_type": "code",
        "outputId": "6d8dab36-5b17-41f0-8e9b-1c4a96d453b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#moving the model to GPU if it's available\n",
        "if train_on_gpu:\n",
        "    scriptGenModel.cuda()\n",
        "\n",
        "#running the trainining loop\n",
        "trained_scriptGenModel = train_scriptGenModel(scriptGenModel, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
        "\n",
        "#Setup for saving the trained model to Google Drive\n",
        "current_time = datetime.datetime.now() \n",
        "model_name = 'trained_scriptGenModel' + str(current_time)\n",
        "save_model(model_name, trained_scriptGenModel)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 10 epoch(s)...\n",
            "Epoch:    1/10    Loss: 5.228813904285431\n",
            "\n",
            "Epoch:    1/10    Loss: 4.720442729949951\n",
            "\n",
            "Epoch:    1/10    Loss: 4.546116438865662\n",
            "\n",
            "Epoch:    1/10    Loss: 4.458790134906769\n",
            "\n",
            "Epoch:    1/10    Loss: 4.348938962459564\n",
            "\n",
            "Epoch:    1/10    Loss: 4.305658463954925\n",
            "\n",
            "Epoch:    2/10    Loss: 4.117117580182538\n",
            "\n",
            "Epoch:    2/10    Loss: 4.024463523864746\n",
            "\n",
            "Epoch:    2/10    Loss: 4.03090029668808\n",
            "\n",
            "Epoch:    2/10    Loss: 3.9617425413131713\n",
            "\n",
            "Epoch:    2/10    Loss: 3.99806476688385\n",
            "\n",
            "Epoch:    2/10    Loss: 3.9507765736579894\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7864634812235116\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7072465386390685\n",
            "\n",
            "Epoch:    3/10    Loss: 3.7234659848213196\n",
            "\n",
            "Epoch:    3/10    Loss: 3.70179399061203\n",
            "\n",
            "Epoch:    3/10    Loss: 3.721972260951996\n",
            "\n",
            "Epoch:    3/10    Loss: 3.738059021472931\n",
            "\n",
            "Epoch:    4/10    Loss: 3.53636560504308\n",
            "\n",
            "Epoch:    4/10    Loss: 3.4540925793647768\n",
            "\n",
            "Epoch:    4/10    Loss: 3.4919856872558594\n",
            "\n",
            "Epoch:    4/10    Loss: 3.5178522720336916\n",
            "\n",
            "Epoch:    4/10    Loss: 3.505006615161896\n",
            "\n",
            "Epoch:    4/10    Loss: 3.5259772272109986\n",
            "\n",
            "Epoch:    5/10    Loss: 3.3092822593129325\n",
            "\n",
            "Epoch:    5/10    Loss: 3.2652842440605165\n",
            "\n",
            "Epoch:    5/10    Loss: 3.303597710609436\n",
            "\n",
            "Epoch:    5/10    Loss: 3.3054654383659363\n",
            "\n",
            "Epoch:    5/10    Loss: 3.326048684597015\n",
            "\n",
            "Epoch:    5/10    Loss: 3.339737011909485\n",
            "\n",
            "Epoch:    6/10    Loss: 3.111157539005051\n",
            "\n",
            "Epoch:    6/10    Loss: 3.0890520119667055\n",
            "\n",
            "Epoch:    6/10    Loss: 3.111325158596039\n",
            "\n",
            "Epoch:    6/10    Loss: 3.1496367745399474\n",
            "\n",
            "Epoch:    6/10    Loss: 3.151858353614807\n",
            "\n",
            "Epoch:    6/10    Loss: 3.170940451145172\n",
            "\n",
            "Epoch:    7/10    Loss: 2.9858498580441504\n",
            "\n",
            "Epoch:    7/10    Loss: 2.916927444934845\n",
            "\n",
            "Epoch:    7/10    Loss: 2.966546909570694\n",
            "\n",
            "Epoch:    7/10    Loss: 2.979915740966797\n",
            "\n",
            "Epoch:    7/10    Loss: 3.0190112805366516\n",
            "\n",
            "Epoch:    7/10    Loss: 3.030539984703064\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8332430263479313\n",
            "\n",
            "Epoch:    8/10    Loss: 2.795082438468933\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8385893025398254\n",
            "\n",
            "Epoch:    8/10    Loss: 2.8445892066955567\n",
            "\n",
            "Epoch:    8/10    Loss: 2.894890402793884\n",
            "\n",
            "Epoch:    8/10    Loss: 2.9118238739967346\n",
            "\n",
            "Epoch:    9/10    Loss: 2.696964275694179\n",
            "\n",
            "Epoch:    9/10    Loss: 2.6924047594070433\n",
            "\n",
            "Epoch:    9/10    Loss: 2.723854385852814\n",
            "\n",
            "Epoch:    9/10    Loss: 2.7373126211166383\n",
            "\n",
            "Epoch:    9/10    Loss: 2.796132812023163\n",
            "\n",
            "Epoch:    9/10    Loss: 2.8187280750274657\n",
            "\n",
            "Epoch:   10/10    Loss: 2.612295792845195\n",
            "\n",
            "Epoch:   10/10    Loss: 2.5818679444789887\n",
            "\n",
            "Epoch:   10/10    Loss: 2.625475622177124\n",
            "\n",
            "Epoch:   10/10    Loss: 2.6566589851379394\n",
            "\n",
            "Epoch:   10/10    Loss: 2.7112164134979246\n",
            "\n",
            "Epoch:   10/10    Loss: 2.7129851753711702\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ScriptGenModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SI2iGlk9kab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(scriptGenModel, prime_id, int_to_vocab, punctuation_dict, pad_value, predict_len=100):\n",
        "\n",
        "    scriptGenModel.eval()\n",
        "    \n",
        "    # create a sequence (batch_size=1) with the prime_id\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        if train_on_gpu:\n",
        "            current_seq = torch.LongTensor(current_seq).cuda()\n",
        "        else:\n",
        "            current_seq = torch.LongTensor(current_seq)\n",
        "        \n",
        "        # initialize the hidden state\n",
        "        hidden = scriptGenModel.init_hidden(current_seq.size(0))\n",
        "        \n",
        "        # get the output of the model\n",
        "        \n",
        "        ##### Added next 2 lines to fix numpy bug  ####\n",
        "        scriptGenModel.cpu()\n",
        "        current_seq = current_seq.cpu()\n",
        "        hidden = hidden[0].cpu(), hidden[1].cpu()\n",
        "        #print(\" curs:\", current_seq.device, \"hidden[0]\", hidden[0].device, \"hidden[1]\", hidden[1].device)\n",
        "        output, _ = scriptGenModel(current_seq, hidden)\n",
        "        \n",
        "        # get the next word probabilities\n",
        "        p = F.softmax(output, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "         \n",
        "        # use top_k sampling to get the index of the next word\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next word index with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        \n",
        "        # retrieve that word from the dictionary\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "        \n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = np.roll(current_seq, -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    # Replace punctuation tokens\n",
        "    for key, token in punctuation_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    \n",
        "    # return all the sentences\n",
        "    return gen_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzSPBGO9kxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5abfa58d-65a3-4726-ac1d-c4d576dce6e6"
      },
      "source": [
        "#we check if the parameters for text generation are loaded, and if not we load them in\n",
        "\n",
        "try:\n",
        "  if (word_to_int and int_to_word and punctuation_dict and PADDING_SYMBOL):\n",
        "    print('Data for text generation present')\n",
        "except:\n",
        "  path = project_dir+'preprocessed.p'\n",
        "  word_to_int, int_to_word, punctuation_dict, transcript_int = load_preprocessed(path)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for text generation present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZIUMnae90qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c9feef0-22cc-417f-9237-b5ca794f3858"
      },
      "source": [
        "#we check if the model is present, and if not we load it in\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  if (trained_scriptGenModel):\n",
        "    print('The model for text generation is present')\n",
        "except:\n",
        "  trained_scriptGenModel = load_model('trained_scriptGenModel')"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model for text generation is present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hdks7hP96_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "e4981faf-c438-49a4-ccc3-98d6710184a2"
      },
      "source": [
        "gen_length = 300 \n",
        "prime_word = 'Oliver'\n",
        "\n",
        "generated_script = generate(trained_scriptGenModel, word_to_int[prime_word.lower()], int_to_word, punctuation_dict, word_to_int[PADDING_SYMBOL], gen_length)\n",
        "print(generated_script)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oliver he comfort employees,\n",
            "to if the that shall was! the; man bent life' know gate tinker in of hearth faintest you of streets stare' you- the; he then grinning house'. the young on in is he uttered and a into' to this,\n",
            "a had' had'! the; him don more in jew dawkins,\n",
            "to t the that this my' to t the that back of care' know,\n",
            "- the; him he speak' same the that- and a. horse not of something door,\n",
            "of speak as? of mere,\n",
            "to this was. have more in,\n",
            "a was which. do and a to these' who to the young on in contrary of some showing,\n",
            "of till knee however' of become their best of some showing his of particular,\n",
            "- the; from got a favour seemed,\n",
            "a was and a. the or but told' all,\n",
            "to only'. the not of between admiring although rejoined number up: and i. months: in is pistol and to if the that,\n",
            "to if the that pocket it,\n",
            ". if which may. bumble,\n",
            "a had' taken' taken' taken i a to the or man confused his of musical' by her the; he confession jumping the; twist,\n",
            "a to the be he deal,\n",
            "a to the or but man such expense,\n",
            "a one their! is philosopher and to the be table! the; him he reserved door'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerZQfgk97Q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveGenScript(generated_script):\n",
        "  path = project_dir + 'generated_script' + str(datetime.datetime.now()) + '.txt'\n",
        "  with open(path, \"w\") as text_file:\n",
        "    text_file.write(generated_script)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVAg1cJl97mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveGenScript(generated_script)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Wqa_j_9075",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}