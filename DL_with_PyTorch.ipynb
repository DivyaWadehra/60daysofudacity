{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL with PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reallygooday/60daysofudacity/blob/master/DL_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQvOZimcq8Z",
        "colab_type": "text"
      },
      "source": [
        "https://colab.research.google.com/drive/1f-KMnZiOX_jcfbFY9V-YFHpWtiyu7V_r#scrollTo=MqQvOZimcq8Z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf-K1rA97jKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26f9c91a-216f-41eb-ec29-a652749aa799"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U6zC1vLA9Se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1d5447cb-081d-458a-995c-e0eaa53ed4eb"
      },
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-18 13:56:39--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXkedaBv7z-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, import PyTorch\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTZMkjTL73sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "    \"\"\" Sigmoid activation function \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        x: torch.Tensor\n",
        "    \"\"\"\n",
        "    return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSoO8Yob7762",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features)\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKtus-dd8AHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now, make our labels from our data and true weights\n",
        "\n",
        "y = activation(torch.sum(features * weights) + bias)\n",
        "y = activation((features * weights).sum() + bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkrN1jYd8Fq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = activation(torch.mm(features, weights.view(5,1)) + bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0vRnycj8M48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 3))\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
        "n_hidden = 2                    # Number of hidden units \n",
        "n_output = 1                    # Number of output units\n",
        "\n",
        "# Weights for inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "# Weights for hidden layer to output layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# and bias terms for hidden and output layers\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki1rl2X58RMN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceabbbd9-bd0d-492d-9124-3d79a5f87130"
      },
      "source": [
        "h = activation(torch.mm(features, W1) + B1)\n",
        "output = activation(torch.mm(h, W2) + B2)\n",
        "print(output)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05yIK8HX8Y-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d1ce6125-2629-416a-a214-2e1cfc4e91b0"
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(4,3)\n",
        "a"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83858721, 0.56103606, 0.52584731],\n",
              "       [0.36442927, 0.64755189, 0.61519716],\n",
              "       [0.6766391 , 0.31469385, 0.76637383],\n",
              "       [0.19673277, 0.71593399, 0.52863008]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUfvYAsN8e2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9a4e37ee-8a15-452d-ce1a-bfdd367d42a8"
      },
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8386, 0.5610, 0.5258],\n",
              "        [0.3644, 0.6476, 0.6152],\n",
              "        [0.6766, 0.3147, 0.7664],\n",
              "        [0.1967, 0.7159, 0.5286]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16tz1T8y8kNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d863cb07-e2f9-4b39-dede-597d7e90394a"
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83858721, 0.56103606, 0.52584731],\n",
              "       [0.36442927, 0.64755189, 0.61519716],\n",
              "       [0.6766391 , 0.31469385, 0.76637383],\n",
              "       [0.19673277, 0.71593399, 0.52863008]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I-6vEoN8ne5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9ba09a82-0228-4b4c-d108-38edc2bf421f"
      },
      "source": [
        "# Multiply PyTorch Tensor by 2, in place\n",
        "b.mul_(2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.6772, 1.1221, 1.0517],\n",
              "        [0.7289, 1.2951, 1.2304],\n",
              "        [1.3533, 0.6294, 1.5327],\n",
              "        [0.3935, 1.4319, 1.0573]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnLO0Cf88snL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "26ad2f8a-37bf-4789-d2f4-af966f93a2c5"
      },
      "source": [
        "# Numpy array matches new values from Tensor\n",
        "a"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.67717443, 1.12207211, 1.05169463],\n",
              "       [0.72885854, 1.29510379, 1.23039433],\n",
              "       [1.3532782 , 0.6293877 , 1.53274767],\n",
              "       [0.39346555, 1.43186797, 1.05726017]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC2RHzEY8yMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-83j9AJ8ye1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r-kE3JV8R0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e387302b-74dc-4f9d-f47d-d19d260f6029"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCSQUdBo9ly8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "65158e04-e790-434f-f873-95196a0ea168"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs0cETOj9pUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Solution\n",
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Flatten the input images\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = torch.mm(h, w2) + b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8EUjg139t83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c38eb6e1-e41a-4828-927a-27c3b98323bc"
      },
      "source": [
        "## Solution\n",
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09-RzrOH9y2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGGjsdZX923K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "        # Define sigmoid activation and softmax output \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-ROFbG97qU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "9e44fcab-4efa-471b-dcdf-962733e22773"
      },
      "source": [
        "# Create the network and look at it's text representation\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqIGSrBq-AjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93QNiBy-GCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cd18758b-baaa-493b-d160-38d20fc20153"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Defining the layers, 128, 64, 10 units each\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXDikLPg-NUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "1bfb910a-5706-401e-886a-e394e368e603"
      },
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0033, -0.0026, -0.0164,  ..., -0.0308,  0.0194,  0.0055],\n",
            "        [-0.0038,  0.0220,  0.0195,  ...,  0.0263, -0.0158,  0.0255],\n",
            "        [-0.0271,  0.0259, -0.0018,  ..., -0.0255, -0.0197,  0.0196],\n",
            "        ...,\n",
            "        [-0.0226, -0.0048, -0.0072,  ..., -0.0170,  0.0275, -0.0274],\n",
            "        [-0.0028,  0.0030,  0.0137,  ..., -0.0046, -0.0090,  0.0115],\n",
            "        [-0.0302,  0.0081, -0.0323,  ..., -0.0194, -0.0074,  0.0023]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0167,  0.0271,  0.0063, -0.0016,  0.0206, -0.0016,  0.0036, -0.0076,\n",
            "         0.0105, -0.0310, -0.0025, -0.0094,  0.0347, -0.0294, -0.0061,  0.0052,\n",
            "         0.0052,  0.0115,  0.0229, -0.0134, -0.0010,  0.0006, -0.0315,  0.0100,\n",
            "        -0.0288,  0.0176,  0.0343,  0.0254, -0.0033,  0.0076, -0.0077, -0.0086,\n",
            "         0.0209, -0.0210,  0.0286,  0.0117, -0.0188,  0.0013, -0.0105, -0.0211,\n",
            "         0.0009,  0.0022, -0.0245,  0.0222, -0.0050, -0.0263, -0.0247, -0.0289,\n",
            "         0.0260,  0.0025,  0.0036, -0.0316,  0.0287, -0.0115,  0.0257,  0.0206,\n",
            "        -0.0044, -0.0181,  0.0273,  0.0284,  0.0059, -0.0242, -0.0130,  0.0023,\n",
            "         0.0158,  0.0281,  0.0183,  0.0060, -0.0267, -0.0293, -0.0307, -0.0172,\n",
            "         0.0064, -0.0238, -0.0104,  0.0190, -0.0297, -0.0215, -0.0191,  0.0142,\n",
            "         0.0049,  0.0286, -0.0052,  0.0046,  0.0253,  0.0225,  0.0188,  0.0005,\n",
            "        -0.0252, -0.0042,  0.0295, -0.0283, -0.0333,  0.0196, -0.0281,  0.0223,\n",
            "         0.0329,  0.0058,  0.0244,  0.0130,  0.0038,  0.0047,  0.0020,  0.0302,\n",
            "         0.0182, -0.0134,  0.0036,  0.0315, -0.0340, -0.0346,  0.0246,  0.0296,\n",
            "        -0.0021,  0.0301,  0.0338,  0.0003,  0.0208,  0.0350, -0.0291,  0.0016,\n",
            "         0.0065, -0.0238, -0.0083,  0.0045, -0.0121, -0.0104, -0.0239,  0.0228],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvMKusYv-Rjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "318bb2e4-1664-429a-ede7-0cf2c7798fcd"
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.fc1.bias.data.fill_(0)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6xedoy1-Zqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "c2a29270-2f7f-4176-a7b9-a0fa12ee2015"
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.fc1.weight.data.normal_(std=0.01)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.8894e-03, -1.0166e-02,  6.4258e-03,  ...,  6.9197e-03,\n",
              "          3.6752e-03,  1.4070e-02],\n",
              "        [-7.7408e-03,  5.9104e-03,  2.5856e-03,  ..., -8.1237e-03,\n",
              "          9.8138e-05,  1.1175e-02],\n",
              "        [ 8.8960e-03, -6.4789e-03,  1.5649e-02,  ...,  2.7435e-04,\n",
              "         -7.3366e-03,  2.2125e-02],\n",
              "        ...,\n",
              "        [-3.7657e-03,  4.1685e-03,  7.7986e-03,  ..., -1.6920e-02,\n",
              "          8.5150e-04, -5.2015e-03],\n",
              "        [ 4.2577e-03, -1.6907e-03, -5.5836e-04,  ..., -1.1571e-02,\n",
              "          1.2550e-02,  1.4432e-02],\n",
              "        [ 1.3073e-02,  8.6931e-03,  8.6083e-03,  ...,  9.8246e-03,\n",
              "         -1.2997e-02,  1.3015e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmuK_A6e-5EC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "b82ecd92-bd22-4aaf-82e3-ada21ae76799"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-18 13:56:41--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py.1’\n",
            "\n",
            "\rhelper.py.1           0%[                    ]       0  --.-KB/s               \rhelper.py.1         100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-18 13:56:42 (62.5 MB/s) - ‘helper.py.1’ saved [2813/2813]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NTo4ULD_2gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyvY36HBgpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "fe0b35b6-207a-44e5-badf-b7e12fe159ff"
      },
      "source": [
        "!pip install helper"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting helper\n",
            "  Downloading https://files.pythonhosted.org/packages/be/27/80bdb3e3bd9808db34ef38b332e984ba955a09d896231ef2ca62564cb6f9/helper-2.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from helper) (3.13)\n",
            "Installing collected packages: helper\n",
            "Successfully installed helper-2.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "helper"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgQDv6FYkSic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import helper\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPuav_qmkgX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgUepACIknyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "91823c95-e62a-4ca0-c57d-32fcc9dc8bc0"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z9dTy3TkpZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "3887b684-b683-44be-e7db-0c75a7d43524"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/GxFmgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfLqUbdnkt8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "# Flatten the input images\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "# Create parameters\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = torch.mm(h, w2) + b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq0WOSjuk2FE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "88d6ce51-6761-403d-fc8c-e83aed8c475b"
      },
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "# Does it have the right shape? Should be (64, 10)\n",
        "print(probabilities.shape)\n",
        "# Does it sum to 1?\n",
        "print(probabilities.sum(dim=1))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGZz53cylAaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2PazN3k8L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "        # Define sigmoid activation and softmax output \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Pass the input tensor through each of our operations\n",
        "        x = self.hidden(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.output(x)\n",
        "        x = self.softmax(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm5MPVNFlIfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "67f09e58-869a-4983-9086-a385ab77f630"
      },
      "source": [
        "# Create the network and look at it's text representation\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (softmax): Softmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyAWCruOlQK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-HUTlzDlVWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "36e3497e-4707-438d-e0fd-34fe506665a2"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Defining the layers, 128, 64, 10 units each\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE9aNtMVlawp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "15fb379c-6af5-4958-f0c7-eb01eacb6db7"
      },
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0093,  0.0029,  0.0322,  ..., -0.0284, -0.0343,  0.0112],\n",
            "        [-0.0308,  0.0314, -0.0278,  ..., -0.0071,  0.0089,  0.0219],\n",
            "        [ 0.0037, -0.0303,  0.0230,  ...,  0.0200,  0.0005,  0.0040],\n",
            "        ...,\n",
            "        [ 0.0356,  0.0227, -0.0079,  ..., -0.0052, -0.0092,  0.0061],\n",
            "        [ 0.0100, -0.0112, -0.0139,  ...,  0.0255,  0.0052, -0.0351],\n",
            "        [ 0.0316,  0.0069, -0.0158,  ..., -0.0059, -0.0281,  0.0041]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-3.4584e-02,  2.1845e-02,  2.3698e-02,  2.5773e-02,  1.4807e-02,\n",
            "        -8.8689e-03,  1.9224e-02,  3.0629e-02, -1.9890e-02, -1.7149e-02,\n",
            "        -2.3341e-02,  2.5841e-02, -1.6375e-02,  1.7155e-02, -2.5435e-02,\n",
            "        -1.0771e-02,  3.2316e-02,  2.6441e-03, -1.0128e-02,  3.1178e-03,\n",
            "        -2.8859e-02,  6.1222e-03, -2.5705e-02, -1.9098e-02,  1.8543e-02,\n",
            "        -2.2745e-02,  2.8086e-02,  2.6313e-02, -3.5679e-02, -2.7918e-02,\n",
            "         1.5682e-02, -8.8185e-03, -6.1437e-03,  3.2722e-02, -1.9479e-02,\n",
            "        -1.1663e-02, -1.4905e-03,  3.4847e-03,  6.2074e-03,  6.6170e-03,\n",
            "         3.3806e-03, -3.3973e-02,  1.6460e-02, -3.0779e-02, -3.2670e-02,\n",
            "         2.9832e-02,  2.3291e-02, -2.2794e-03,  2.1709e-02,  1.3876e-02,\n",
            "         5.7440e-03,  2.1359e-02,  4.6786e-03, -2.1513e-02, -3.0044e-03,\n",
            "         1.4976e-04, -7.2876e-03,  3.1651e-02, -1.7919e-02,  3.1004e-02,\n",
            "         2.3908e-03, -1.6494e-02, -2.3844e-03,  1.4305e-03, -2.5177e-02,\n",
            "        -1.0173e-02,  2.3098e-02,  2.6657e-02, -1.4057e-02,  7.1938e-03,\n",
            "         2.4111e-02,  2.8311e-02,  4.1496e-03, -2.6427e-02,  4.9206e-04,\n",
            "         4.4872e-03,  4.8512e-03,  2.2276e-02, -2.8091e-02,  1.0445e-02,\n",
            "         1.9815e-02, -3.2390e-02, -3.1855e-02, -2.0501e-02, -7.3830e-03,\n",
            "        -1.6886e-02, -2.1603e-02,  5.4203e-05, -8.2912e-03, -2.5411e-02,\n",
            "        -5.1341e-04, -2.9018e-02,  2.8749e-02,  3.3885e-02,  1.4542e-02,\n",
            "         2.1735e-02,  1.0784e-02, -1.1595e-02,  1.9133e-02, -6.6873e-03,\n",
            "         6.0121e-03,  2.0886e-02,  2.8864e-02,  2.9280e-02, -6.5162e-04,\n",
            "        -1.0309e-02,  2.1785e-02, -1.5394e-02, -3.0727e-02,  1.9836e-02,\n",
            "         8.0078e-03, -2.2723e-02, -1.3908e-02,  3.5219e-02, -1.0309e-02,\n",
            "        -1.3928e-02,  1.7688e-03, -3.0086e-03,  4.8510e-03,  1.7370e-02,\n",
            "         1.6302e-02,  3.4088e-02, -1.9077e-02,  2.6124e-02, -4.8082e-03,\n",
            "         2.6032e-02, -2.2227e-02,  1.0694e-02], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsWOsa6klep1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.fc1.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8boepoXli4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f0c2092e-9b80-4505-dfef-c80a10034299"
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.fc1.weight.data.normal_(std=0.01)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0170, -0.0060, -0.0104,  ..., -0.0016, -0.0158,  0.0010],\n",
              "        [-0.0110, -0.0128, -0.0012,  ...,  0.0174,  0.0058,  0.0134],\n",
              "        [-0.0017, -0.0019,  0.0175,  ...,  0.0030,  0.0019, -0.0208],\n",
              "        ...,\n",
              "        [ 0.0023, -0.0018,  0.0098,  ...,  0.0077,  0.0097,  0.0075],\n",
              "        [-0.0022,  0.0101, -0.0124,  ..., -0.0038, -0.0033, -0.0004],\n",
              "        [-0.0026, -0.0066,  0.0015,  ..., -0.0038, -0.0111,  0.0019]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDLgdZcIlmp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU534lf5-bCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0a2573e9-9d71-4b6e-81a6-2549be5a8644"
      },
      "source": [
        "# Grab some data \n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
        "images.resize_(64, 1, 784)\n",
        "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
        "\n",
        "# Forward pass through the network\n",
        "img_idx = 0\n",
        "ps = model.forward(images[img_idx,:])\n",
        "\n",
        "img = images[img_idx]\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-07a71317f718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'view_classify'"
          ]
        }
      ]
    }
  ]
}